{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5781b85-b847-49cc-a5fe-084dd84c9f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\admin\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from lightgbm) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\anaconda3\\lib\\site-packages (from lightgbm) (1.13.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "057fbf4f-1b9b-4375-89cf-7727c0fbeeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3215b2cf-8bde-4c86-9201-af01a97b0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the encoded train and test data\n",
    "# Load the data into memory (no mmap_mode)\n",
    "Train_data = joblib.load('encoded_train_data1.joblib')\n",
    "Test_data = joblib.load('encoded_test_data1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2e145f6-0c7a-41a7-b5f0-0b483819333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separateing features (X) and target variable (y)\n",
    "X = Train_data.drop(columns=['IncidentGrade'])\n",
    "y = Train_data['IncidentGrade']\n",
    "\n",
    "# Spliting the data (80:20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a408c0e-13d3-4134-bc8e-71a867711fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Accuracy: 0.5616696298351134\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.87      0.66    416110\n",
      "           1       0.47      0.07      0.12    203156\n",
      "           2       0.69      0.47      0.56    332418\n",
      "\n",
      "    accuracy                           0.56    951684\n",
      "   macro avg       0.56      0.47      0.44    951684\n",
      "weighted avg       0.57      0.56      0.51    951684\n",
      "\n",
      "Confusion Matrix:\n",
      "[[363085   8387  44638]\n",
      " [161550  13874  27732]\n",
      " [167529   7316 157573]]\n",
      "--------------------------------------------------\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9336323821772773\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94    416110\n",
      "           1       0.95      0.88      0.91    203156\n",
      "           2       0.96      0.92      0.94    332418\n",
      "\n",
      "    accuracy                           0.93    951684\n",
      "   macro avg       0.94      0.92      0.93    951684\n",
      "weighted avg       0.94      0.93      0.93    951684\n",
      "\n",
      "Confusion Matrix:\n",
      "[[403873   5712   6525]\n",
      " [ 19692 178121   5343]\n",
      " [ 21663   4226 306529]]\n",
      "--------------------------------------------------\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.9555945040580697\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96    416110\n",
      "           1       0.93      0.93      0.93    203156\n",
      "           2       0.96      0.96      0.96    332418\n",
      "\n",
      "    accuracy                           0.96    951684\n",
      "   macro avg       0.95      0.95      0.95    951684\n",
      "weighted avg       0.96      0.96      0.96    951684\n",
      "\n",
      "Confusion Matrix:\n",
      "[[400544   8183   7383]\n",
      " [  7915 189530   5711]\n",
      " [  7151   5917 319350]]\n",
      "--------------------------------------------------\n",
      "Model: Gradient Boosting\n",
      "Accuracy: 0.7980653242042527\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82    416110\n",
      "           1       0.88      0.57      0.69    203156\n",
      "           2       0.93      0.74      0.82    332418\n",
      "\n",
      "    accuracy                           0.80    951684\n",
      "   macro avg       0.84      0.76      0.78    951684\n",
      "weighted avg       0.83      0.80      0.79    951684\n",
      "\n",
      "Confusion Matrix:\n",
      "[[398091   9114   8905]\n",
      " [ 76773 116193  10190]\n",
      " [ 81108   6088 245222]]\n",
      "--------------------------------------------------\n",
      "Model: XGBoost\n",
      "Accuracy: 0.9153637131652944\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92    416110\n",
      "           1       0.93      0.85      0.89    203156\n",
      "           2       0.94      0.90      0.92    332418\n",
      "\n",
      "    accuracy                           0.92    951684\n",
      "   macro avg       0.92      0.90      0.91    951684\n",
      "weighted avg       0.92      0.92      0.92    951684\n",
      "\n",
      "Confusion Matrix:\n",
      "[[399091   7365   9654]\n",
      " [ 23503 171830   7823]\n",
      " [ 26885   5317 300216]]\n",
      "--------------------------------------------------\n",
      "Model: LightGBM\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093921 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2190\n",
      "[LightGBM] [Info] Number of data points in the train set: 380673, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -0.828430\n",
      "[LightGBM] [Info] Start training from score -1.541166\n",
      "[LightGBM] [Info] Start training from score -1.052299\n",
      "Accuracy: 0.8910100411481122\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.96      0.90    416110\n",
      "           1       0.93      0.78      0.85    203156\n",
      "           2       0.94      0.87      0.91    332418\n",
      "\n",
      "    accuracy                           0.89    951684\n",
      "   macro avg       0.91      0.87      0.88    951684\n",
      "weighted avg       0.90      0.89      0.89    951684\n",
      "\n",
      "Confusion Matrix:\n",
      "[[399148   6992   9970]\n",
      " [ 36138 158564   8454]\n",
      " [ 37383   4787 290248]]\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Function to evaluate a model\n",
    "def evaluate_model(model, X_train, y_train, X_val, y_val):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy and generate the classification report and confusion matrix\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    report = classification_report(y_val, y_pred)\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "    \n",
    "    # Return results as a dictionary for further use or display\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "# Subsample your training data for faster evaluation\n",
    "X_train_subsample = X_train.sample(frac=0.1, random_state=42)\n",
    "y_train_subsample = y_train.loc[X_train_subsample.index]\n",
    "\n",
    "# Define your models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_jobs=-1, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_jobs=-1, random_state=42),\n",
    "    'LightGBM': LGBMClassifier(n_jobs=-1, random_state=42),\n",
    "}\n",
    "\n",
    "# Loop through models, evaluate and display the results\n",
    "for model_name, model in models.items():\n",
    "    print(f'Model: {model_name}')\n",
    "    \n",
    "    # Evaluate the model using the function\n",
    "    evaluation_results = evaluate_model(model, X_train_subsample, y_train_subsample, X_val, y_val)\n",
    "    \n",
    "    # Display the evaluation results\n",
    "    print(f'Accuracy: {evaluation_results[\"accuracy\"]}')\n",
    "    print('Classification Report:')\n",
    "    print(evaluation_results[\"classification_report\"])\n",
    "    print('Confusion Matrix:')\n",
    "    print(evaluation_results[\"confusion_matrix\"])\n",
    "    print('-' * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8578e590-2ebe-4011-977e-b14f31848c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison Table:\n",
      "              Model  Accuracy  Macro-F1 Score  Precision  Recall\n",
      "Logistic Regression      0.56            0.44       0.56    0.47\n",
      "      Decision Tree      0.93            0.93       0.94    0.92\n",
      "      Random Forest      0.96            0.95       0.93    0.95\n",
      "            XGBoost      0.92            0.91       0.92    0.90\n",
      "           LightGBM      0.89            0.88       0.91    0.87\n",
      "  Gradient Boosting      0.80            0.78       0.84    0.76\n",
      "\n",
      "Best Model Based on Macro-F1 Score (and Accuracy in case of a tie):\n",
      "Model             Random Forest\n",
      "Accuracy                   0.96\n",
      "Macro-F1 Score             0.95\n",
      "Precision                  0.93\n",
      "Recall                     0.95\n",
      "Name: 2, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create the report data as a dictionary\n",
    "report = {\n",
    "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'LightGBM', 'Gradient Boosting'],\n",
    "    'Accuracy': [0.56, 0.93, 0.96, 0.92, 0.89, 0.8],\n",
    "    'Macro-F1 Score': [0.44, 0.93, 0.95, 0.91, 0.88, 0.78],\n",
    "    'Precision': [0.56, 0.94, 0.93, 0.92, 0.91, 0.84],\n",
    "    'Recall': [0.47, 0.92, 0.95, 0.90, 0.87, 0.76]\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "df = pd.DataFrame(report)\n",
    "\n",
    "# Display the comparison table\n",
    "print(\"Comparison Table:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Sort the DataFrame by 'Macro-F1 Score' in descending order, and 'Accuracy' in case of a tie\n",
    "best_model = df.sort_values(by=['Macro-F1 Score', 'Accuracy'], ascending=[False, False]).iloc[0]\n",
    "\n",
    "# Display the best model\n",
    "print(\"\\nBest Model Based on Macro-F1 Score (and Accuracy in case of a tie):\")\n",
    "print(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5b0401f-fe84-44ca-8cc1-262983e11db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Hyperparameters: {'n_estimators': 75, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90    416110\n",
      "           1       0.87      0.84      0.85    203156\n",
      "           2       0.93      0.88      0.91    332418\n",
      "\n",
      "    accuracy                           0.89    951684\n",
      "   macro avg       0.89      0.88      0.89    951684\n",
      "weighted avg       0.90      0.89      0.89    951684\n",
      "\n",
      "Confusion Matrix:\n",
      "[[387517  15783  12810]\n",
      " [ 24329 170452   8375]\n",
      " [ 29289  10034 293095]]\n",
      "Model saved as rf_smote_tuned_model.joblib\n"
     ]
    }
   ],
   "source": [
    "#Applying SMOTE to the training data for class imbalance and doing hyperparameter tuning for best result\n",
    "# Loading the encoded train data\n",
    "train_data = joblib.load('encoded_train_data1.joblib')\n",
    "\n",
    "# Separating the features (X) and target variable (y)\n",
    "X = train_data.drop('IncidentGrade', axis=1)\n",
    "y = train_data['IncidentGrade']\n",
    "\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "# Splitting the data (80:20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Downsampling the training data to 2% for quicker processing\n",
    "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, train_size=0.02, stratify=y_train, random_state=42)\n",
    "\n",
    "if X_train_sampled.select_dtypes(include=['bool']).shape[1] > 0:\n",
    "    X_train_sampled = X_train_sampled.astype(int)\n",
    "\n",
    "# Applying SMOTE for multi-class classification (default strategy balances all classes equally)\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# Hyperparameters for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 75],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=5,\n",
    "                                   cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fitting the Randomized Search with resampled training data\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best parameters and model\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Evaluating on validation data\n",
    "y_pred = best_rf.predict(X_val)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "# Saving the tuned model\n",
    "joblib.dump(best_rf, \"rf_smote_tuned_model.joblib\")\n",
    "print(\"Model saved as rf_smote_tuned_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6f2d80-546d-4706-a75f-17b09d9451fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82   1630942\n",
      "           1       0.66      0.88      0.75    868897\n",
      "           2       0.89      0.87      0.88   1422856\n",
      "\n",
      "    accuracy                           0.83   3922695\n",
      "   macro avg       0.82      0.84      0.82   3922695\n",
      "weighted avg       0.84      0.83      0.83   3922695\n",
      "\n",
      "\n",
      "Macro-F1 Score: 0.82\n",
      "Macro Precision: 0.82\n",
      "Macro Recall: 0.84\n",
      "\n",
      "Confusion Matrix on Test Data:\n",
      "[[1238943  285302  106697]\n",
      " [  65848  761592   41457]\n",
      " [  69741  109928 1243187]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluation of Best Random Forest Model on Test Data\n",
    "# Loading the saved Random Forest model\n",
    "best_rf = joblib.load(\"rf_smote_tuned_model.joblib\")\n",
    "\n",
    "# Loading the test dataset\n",
    "test_data = joblib.load('encoded_test_data1.joblib')\n",
    "\n",
    "# Separateing the features and target from test data\n",
    "X_test = test_data.drop('IncidentGrade', axis=1)  \n",
    "y_test = test_data['IncidentGrade']\n",
    "\n",
    "# Makeing predictions on the test data\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluateing the saved model on the test data\n",
    "print(\"\\nClassification Report on Test Data:\")\n",
    "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "macro_f1 = report['macro avg']['f1-score']\n",
    "macro_precision = report['macro avg']['precision']\n",
    "macro_recall = report['macro avg']['recall']\n",
    "\n",
    "print(\"\\nMacro-F1 Score: {:.2f}\".format(macro_f1))\n",
    "print(\"Macro Precision: {:.2f}\".format(macro_precision))\n",
    "print(\"Macro Recall: {:.2f}\".format(macro_recall))\n",
    "print(\"\\nConfusion Matrix on Test Data:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ebfd94-58ca-4e18-9f89-a37ce3545fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying SMOTE-ENN to the training data for class imbalance and doing hyperparameter tuning for best result\n",
    "#(SMOTE + Edited Nearest Neighbors)\n",
    "\n",
    "#SMOTE: Adds synthetic samples to balance the classes.\n",
    "#SMOTE-ENN: Adds synthetic samples and then removes noisy or ambiguous samples for better data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d38e926-d2ca-4cad-babc-66313038bb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best Hyperparameters: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84    416110\n",
      "           1       0.70      0.81      0.76    203156\n",
      "           2       0.94      0.76      0.84    332418\n",
      "\n",
      "    accuracy                           0.82    951684\n",
      "   macro avg       0.82      0.81      0.81    951684\n",
      "weighted avg       0.83      0.82      0.82    951684\n",
      "\n",
      "Confusion Matrix:\n",
      "[[361764  43289  11057]\n",
      " [ 31838 165559   5759]\n",
      " [ 54794  26006 251618]]\n",
      "Model saved as rf_smote_enn_tuned_model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Loading the encoded train data\n",
    "train_data = joblib.load('encoded_train_data1.joblib')\n",
    "\n",
    "# Separating the features (X) and target variable (y)\n",
    "X = train_data.drop('IncidentGrade', axis=1)\n",
    "y = train_data['IncidentGrade']\n",
    "\n",
    "X = X.apply(pd.to_numeric, errors='coerce')\n",
    "X = X.dropna(axis=1)\n",
    "\n",
    "# Splitting the data (80:20)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Downsampling the training data to 2% for quicker processing\n",
    "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, train_size=0.02, stratify=y_train, random_state=42)\n",
    "\n",
    "if X_train_sampled.select_dtypes(include=['bool']).shape[1] > 0:\n",
    "    X_train_sampled = X_train_sampled.astype(int)\n",
    "\n",
    "# Applying SMOTE for multi-class classification (default strategy balances all classes equally)\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote_enn.fit_resample(X_train_sampled, y_train_sampled)\n",
    "\n",
    "# Hyperparameters for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 75],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, n_iter=5,\n",
    "                                   cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Fitting the Randomized Search with resampled training data\n",
    "random_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best parameters and model\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Evaluating on validation data\n",
    "y_pred = best_rf.predict(X_val)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "# Saving the tuned model\n",
    "joblib.dump(best_rf, \"rf_smote_enn_tuned_model.joblib\")\n",
    "print(\"Model saved as rf_smote_enn_tuned_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167cf667-e1a3-473b-80fe-6a9a5e653706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report on Test Data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.76      0.82   1630942\n",
      "           1       0.66      0.88      0.75    868897\n",
      "           2       0.89      0.87      0.88   1422856\n",
      "\n",
      "    accuracy                           0.83   3922695\n",
      "   macro avg       0.82      0.84      0.82   3922695\n",
      "weighted avg       0.84      0.83      0.83   3922695\n",
      "\n",
      "\n",
      "Macro-F1 Score: 0.82\n",
      "Macro Precision: 0.82\n",
      "Macro Recall: 0.84\n",
      "\n",
      "Confusion Matrix on Test Data:\n",
      "[[1238947  285291  106704]\n",
      " [  65848  761589   41460]\n",
      " [  69747  109962 1243147]]\n"
     ]
    }
   ],
   "source": [
    "#finally predicting on test data using \n",
    "# Loading the saved Random Forest model\n",
    "best_rf = joblib.load(\"rf_smote_tuned_model.joblib\")\n",
    "\n",
    "# Loading the test dataset\n",
    "test_data = joblib.load('encoded_test_data1.joblib')\n",
    "\n",
    "# Separateing the features and target from test data\n",
    "X_test = test_data.drop('IncidentGrade', axis=1)  \n",
    "y_test = test_data['IncidentGrade']\n",
    "\n",
    "# Makeing predictions on the test data\n",
    "y_test_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluateing the saved model on the test data\n",
    "print(\"\\nClassification Report on Test Data:\")\n",
    "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "macro_f1 = report['macro avg']['f1-score']\n",
    "macro_precision = report['macro avg']['precision']\n",
    "macro_recall = report['macro avg']['recall']\n",
    "\n",
    "print(\"\\nMacro-F1 Score: {:.2f}\".format(macro_f1))\n",
    "print(\"Macro Precision: {:.2f}\".format(macro_precision))\n",
    "print(\"Macro Recall: {:.2f}\".format(macro_recall))\n",
    "print(\"\\nConfusion Matrix on Test Data:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19e6b01-164f-457e-bb9e-d3f5fee18398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
